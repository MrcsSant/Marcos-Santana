{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1pJUH6pri7oL/usIskKIL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Automated URL Audit and Evidence Collection System**\n","\n","This project automates the auditing of URLs associated with business records by:\n","\n","* Reading structured input data from Excel files\n","* Visiting external links using a headless browser\n","* Capturing full-page screenshots as evidence\n","* Flagging missing, internal, or inaccessible links\n","* Generating a consolidated audit report and downloadable evidence package\n","\n","It is designed to reduce manual review effort, increase audit consistency, and produce traceable visual evidence at scale, making it especially useful for compliance checks, sales operations reviews, and internal validation processes.\n","\n","*Upload the Quota Relief File here with the links, change the name of the file on the \"Automated URL Auditing, Screenshot Capture, and Evidence Generation\" Cell*"],"metadata":{"id":"A4y9yVuhr8rU"}},{"cell_type":"markdown","source":["## **Selenium and Web Automation Dependencies Installation**\n","\n","Description:\n","This step installs Selenium, the Chromium browser, and ChromeDriver, along with webdriver-manager, setting up the environment for automated web browsing and testing."],"metadata":{"id":"oIcST9e_qn8j"}},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"id":"rULB1Nd0Pib1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1771525589635,"user_tz":180,"elapsed":50173,"user":{"displayName":"Marcos Vinicius Santana","userId":"17193819781821316839"}},"outputId":"4da6604f-18f1-42cf-a272-83cb0760d17f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.40.0-py3-none-any.whl.metadata (7.7 kB)\n","Requirement already satisfied: certifi>=2026.1.4 in /usr/local/lib/python3.12/dist-packages (from selenium) (2026.1.4)\n","Collecting trio<1.0,>=0.31.0 (from selenium)\n","  Downloading trio-0.33.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Collecting trio-typing>=0.10.0 (from selenium)\n","  Downloading trio_typing-0.10.0-py3-none-any.whl.metadata (10 kB)\n","Collecting types-certifi>=2021.10.8.3 (from selenium)\n","  Downloading types_certifi-2021.10.8.3-py3-none-any.whl.metadata (1.4 kB)\n","Collecting types-urllib3>=1.26.25.14 (from selenium)\n","  Downloading types_urllib3-1.26.25.14-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n","Collecting urllib3<3.0,>=2.6.3 (from urllib3[socks]<3.0,>=2.6.3->selenium)\n","  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n","Collecting sortedcontainers (from trio<1.0,>=0.31.0->selenium)\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n","Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n","Collecting mypy-extensions>=0.4.2 (from trio-typing>=0.10.0->selenium)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting async-generator (from trio-typing>=0.10.0->selenium)\n","  Downloading async_generator-1.10-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from trio-typing>=0.10.0->selenium) (26.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from trio-typing>=0.10.0->selenium) (8.7.1)\n","Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n","  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.6.3->selenium) (1.7.1)\n","Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->trio-typing>=0.10.0->selenium) (3.23.0)\n","Downloading selenium-4.40.0-py3-none-any.whl (9.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio-0.33.0-py3-none-any.whl (510 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.3/510.3 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_typing-0.10.0-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading types_certifi-2021.10.8.3-py3-none-any.whl (2.1 kB)\n","Downloading types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n","Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n","Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Installing collected packages: types-urllib3, types-certifi, sortedcontainers, wsproto, urllib3, outcome, mypy-extensions, async-generator, trio, trio-websocket, trio-typing, selenium\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.5.0\n","    Uninstalling urllib3-2.5.0:\n","      Successfully uninstalled urllib3-2.5.0\n","Successfully installed async-generator-1.10 mypy-extensions-1.1.0 outcome-1.3.0.post0 selenium-4.40.0 sortedcontainers-2.4.0 trio-0.33.0 trio-typing-0.10.0 trio-websocket-0.12.2 types-certifi-2021.10.8.3 types-urllib3-1.26.25.14 urllib3-2.6.3 wsproto-1.3.2\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:2 https://cli.github.com/packages stable InRelease [3,917 B]\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [85.0 kB]\n","Get:8 https://cli.github.com/packages stable/main amd64 Packages [355 B]\n","Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n","Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,756 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,301 kB]\n","Get:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,613 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,737 kB]\n","Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [39.2 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,538 kB]\n","Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,904 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,070 kB]\n","Get:21 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,749 kB]\n","Fetched 37.4 MB in 5s (8,030 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","80 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  apparmor libfuse3-3 snapd squashfs-tools systemd-hwe-hwdb udev\n","Suggested packages:\n","  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n","The following NEW packages will be installed:\n","  apparmor chromium-browser chromium-codecs-ffmpeg libfuse3-3 snapd\n","  squashfs-tools systemd-hwe-hwdb udev\n","0 upgraded, 8 newly installed, 0 to remove and 80 not upgraded.\n","Need to get 34.7 MB of archives.\n","After this operation, 135 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.5 [599 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.17 [1,557 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.73+ubuntu22.04 [32.3 MB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-codecs-ffmpeg amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [3,008 B]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.6 [3,668 B]\n","Fetched 34.7 MB in 3s (11.9 MB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package apparmor.\n","(Reading database ... 117540 files and directories currently installed.)\n","Preparing to unpack .../apparmor_3.0.4-2ubuntu2.5_amd64.deb ...\n","Unpacking apparmor (3.0.4-2ubuntu2.5) ...\n","Selecting previously unselected package squashfs-tools.\n","Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n","Unpacking squashfs-tools (1:4.5-3build1) ...\n","Selecting previously unselected package udev.\n","Preparing to unpack .../udev_249.11-0ubuntu3.17_amd64.deb ...\n","Unpacking udev (249.11-0ubuntu3.17) ...\n","Selecting previously unselected package libfuse3-3:amd64.\n","Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n","Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n","Selecting previously unselected package snapd.\n","Preparing to unpack .../snapd_2.73+ubuntu22.04_amd64.deb ...\n","Unpacking snapd (2.73+ubuntu22.04) ...\n","Setting up apparmor (3.0.4-2ubuntu2.5) ...\n","Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n","Setting up squashfs-tools (1:4.5-3build1) ...\n","Setting up udev (249.11-0ubuntu3.17) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n","Setting up snapd (2.73+ubuntu22.04) ...\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n","Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n","Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n","Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n","Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n","Selecting previously unselected package chromium-browser.\n","(Reading database ... 117974 files and directories currently installed.)\n","Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","=> Installing the chromium snap\n","==> Checking connectivity with the snap store\n","===> System doesn't have a working snapd, skipping\n","Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package chromium-codecs-ffmpeg.\n","Preparing to unpack .../chromium-codecs-ffmpeg_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Selecting previously unselected package systemd-hwe-hwdb.\n","Preparing to unpack .../systemd-hwe-hwdb_249.11.6_all.deb ...\n","Unpacking systemd-hwe-hwdb (249.11.6) ...\n","Setting up chromium-codecs-ffmpeg (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","Setting up systemd-hwe-hwdb (249.11.6) ...\n","Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n","Processing triggers for udev (249.11-0ubuntu3.17) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Collecting webdriver-manager\n","  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (2.32.4)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.2.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (26.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (2.6.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (2026.1.4)\n","Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n","Installing collected packages: webdriver-manager\n","Successfully installed webdriver-manager-4.0.2\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","0 upgraded, 0 newly installed, 0 to remove and 80 not upgraded.\n"]}],"source":["# Install the Selenium package\n","!pip install selenium\n","# Install Chromium (the open-source version of Chrome) and the necessary driver\n","!apt update\n","!apt install chromium-browser chromium-codecs-ffmpeg\n","# Install webdriver-manager for automatic ChromeDriver management\n","!pip install webdriver-manager\n","!apt --fix-broken install"]},{"cell_type":"markdown","source":["## **Environment Setup, Gemini Model Initialization, and System Health Check**\n","\n","Description:\n","This section installs and configures Chrome for headless Selenium execution, initializes the Gemini Flash model using a Google API key, and performs health checks to ensure both the WebDriver and the AI model are working correctly before continuing execution."],"metadata":{"id":"PUD7Vlxhq7UX"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"id":"d39a75c9","outputId":"453d37b4-cba9-4d80-8f13-f13e90040a76","executionInfo":{"status":"ok","timestamp":1771525642697,"user_tz":180,"elapsed":53005,"user":{"displayName":"Marcos Vinicius Santana","userId":"17193819781821316839"}},"collapsed":true},"source":["import sys\n","from selenium import webdriver\n","from selenium.webdriver.chrome.options import Options\n","from selenium.webdriver.chrome.service import Service # Import Service\n","from selenium.common.exceptions import WebDriverException\n","from webdriver_manager.chrome import ChromeDriverManager # Import ChromeDriverManager\n","import google.generativeai as genai\n","from google.colab import userdata\n","from google.colab.userdata import SecretNotFoundError\n","import time\n","import os # Import os for path checking, was missing in original cell\n","\n","# 1. Unconditionally install google-chrome-stable and set its path\n","print(\"Attempting to install google-chrome-stable...\")\n","!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -q\n","!dpkg -i google-chrome-stable_current_amd64.deb > /dev/null\n","!apt-get install -f -y > /dev/null # Fix broken dependencies\n","chrome_binary_path = '/usr/bin/google-chrome'\n","\n","if os.path.exists(chrome_binary_path):\n","    print(\"Google Chrome installed and set as binary path.\")\n","else:\n","    print(\"Failed to install Google Chrome. Falling back to chromium-browser...\")\n","    !apt-get update -qq > /dev/null\n","    !apt-get install -y chromium-browser > /dev/null\n","    chrome_binary_path = '/usr/bin/chromium-browser'\n","    if os.path.exists(chrome_binary_path):\n","        print(\"Using chromium-browser binary as fallback.\")\n","    else:\n","        print(\"Neither Google Chrome nor Chromium Browser found. WebDriver will likely fail.\")\n","\n","# 2. Configure Chrome Headless browser options globally\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","chrome_options.add_argument('--window-size=1280,1920')\n","chrome_options.add_argument('--disable-gpu') # Re-added for better headless stability\n","chrome_options.page_load_strategy = 'eager'\n","chrome_options.binary_location = chrome_binary_path # Use the determined binary path\n","\n","print(\"Chrome Headless browser options configured with binary location.\")\n","\n","# 3. Initialize the Gemini 1.5 Flash model globally\n","try:\n","    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n","    genai.configure(api_key=GOOGLE_API_KEY)\n","\n","    generation_config = {\n","        \"response_mime_type\": \"application/json\",\n","    }\n","\n","    global model # Make model globally accessible\n","    # First, list models to find the correct 1.5 Flash model name\n","    available_models = [m.name for m in genai.list_models() if \"generateContent\" in m.supported_generation_methods]\n","    flash_model_name = None\n","    for m_name in available_models:\n","        if 'gemini-2.5-flash' in m_name: # Updated to search for gemini-2.5-flash\n","            flash_model_name = m_name\n","            break\n","\n","    if flash_model_name:\n","        model = genai.GenerativeModel(\n","            flash_model_name,\n","            generation_config=generation_config\n","        )\n","        print(f\"Gemini model initialized with: {flash_model_name}\")\n","    else:\n","        raise ValueError(\"Gemini Flash model (e.g., 2.5-flash) not found among available models.\") # Updated error message\n","\n","except SecretNotFoundError:\n","    print(\"--------------------------------------------------------------------------------\")\n","    print(\"ERROR: 'GOOGLE_API_KEY' not found in Colab secrets.\")\n","    print(\"Please set your Google API Key in Colab secrets by following these steps:\")\n","    print(\"1. Click on the 'key' icon (Secrets) in the left sidebar of Google Colab.\")\n","    print(\"2. Click '+ New secret'.\")\n","    print(\"3. For 'Name', enter 'GOOGLE_API_KEY'.\")\n","    print(\"4. For 'Value', paste your actual Google API Key.\")\n","    print(\"5. Make sure 'Notebook access' is turned on for this secret.\")\n","    print(\"6. After saving the secret, please re-run this cell.\")\n","    print(\"--------------------------------------------------------------------------------\")\n","    sys.exit(\"Terminating execution: GOOGLE_API_KEY not set.\")\n","except Exception as e:\n","    print(f\"An unexpected error occurred during API key retrieval or Gemini model initialization: {e}\")\n","    sys.exit(f\"Terminating execution: Gemini model initialization failed. Error: {e}\")\n","\n","# 4. System Health Check (Fail-Fast)\n","print(\"\\n--- Performing System Health Check ---\")\n","web_driver_ready = False\n","gemini_model_ready = False\n","\n","# Check WebDriver\n","try:\n","    # Use ChromeDriverManager to get the path to the ChromeDriver executable\n","    # Pass the executable path to a Service object, then pass the service and options to webdriver.Chrome\n","    service = Service(ChromeDriverManager().install())\n","    driver = webdriver.Chrome(service=service, options=chrome_options)\n","    driver.get(\"http://example.com\")\n","    if \"Example Domain\" in driver.title:\n","        web_driver_ready = True\n","        print(\"WebDriver check: SUCCESS. Can launch Chrome and navigate.\")\n","    else:\n","        print(f\"WebDriver check: FAILED. Unexpected title: {driver.title}\")\n","    driver.quit()\n","except WebDriverException as e:\n","    print(f\"WebDriver check: FAILED. Error launching or navigating: {e}\")\n","except Exception as e:\n","    print(f\"WebDriver check: FAILED. Unexpected error: {e}\")\n","\n","# Check Gemini model\n","if 'model' in globals(): # Ensure 'model' variable exists\n","    try:\n","        response = model.generate_content(\"Say 'Hello' in JSON format.\")\n","        # More robust check for JSON response containing 'Hello'\n","        import json\n","        try:\n","            json_response = json.loads(response.text)\n","            if any('Hello' in str(v) for v in json_response.values()): # Check if 'Hello' is in any value of the JSON\n","                gemini_model_ready = True\n","                print(\"Gemini model check: SUCCESS. Can generate content and parse JSON.\")\n","            else:\n","                print(f\"Gemini model check: FAILED. 'Hello' not found in JSON response: {response.text}\")\n","        except json.JSONDecodeError:\n","            print(f\"Gemini model check: FAILED. Response is not valid JSON: {response.text}\")\n","    except Exception as e:\n","        print(f\"Gemini model check: FAILED. Error generating content: {e}\")\n","else:\n","    print(\"Gemini model check: SKIPPED. 'model' object not defined (likely due to missing API key).\")\n","\n","\n","if web_driver_ready and gemini_model_ready:\n","    print(\"\\nSYSTEM GREEN: Proceeding to audit...\")\n","else:\n","    print(\"\\nSYSTEM RED: Critical components not ready. Please review errors above.\")\n","    sys.exit(\"Terminating execution due to system health check failure.\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n","\n","All support for the `google.generativeai` package has ended. It will no longer be receiving \n","updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n","See README for more details:\n","\n","https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n","\n","  loader.exec_module(module)\n"]},{"output_type":"stream","name":"stdout","text":["Attempting to install google-chrome-stable...\n","dpkg: dependency problems prevent configuration of google-chrome-stable:\n"," google-chrome-stable depends on libatk-bridge2.0-0 (>= 2.5.3); however:\n","  Package libatk-bridge2.0-0 is not installed.\n"," google-chrome-stable depends on libatk1.0-0 (>= 2.11.90); however:\n","  Package libatk1.0-0 is not installed.\n"," google-chrome-stable depends on libatspi2.0-0 (>= 2.9.90); however:\n","  Package libatspi2.0-0 is not installed.\n"," google-chrome-stable depends on libvulkan1; however:\n","  Package libvulkan1 is not installed.\n"," google-chrome-stable depends on libxcomposite1 (>= 1:0.4.4-1); however:\n","  Package libxcomposite1 is not installed.\n","\n","dpkg: error processing package google-chrome-stable (--install):\n"," dependency problems - leaving unconfigured\n","Errors were encountered while processing:\n"," google-chrome-stable\n","Google Chrome installed and set as binary path.\n","Chrome Headless browser options configured with binary location.\n","Gemini model initialized with: models/gemini-2.5-flash\n","\n","--- Performing System Health Check ---\n","WebDriver check: SUCCESS. Can launch Chrome and navigate.\n","Gemini model check: SUCCESS. Can generate content and parse JSON.\n","\n","SYSTEM GREEN: Proceeding to audit...\n"]}]},{"cell_type":"markdown","source":["## **Automated URL Auditing, Screenshot Capture, and Evidence Generation**\n","\n","Description:\n","This section reads input data from an Excel file, navigates to extracted URLs using Selenium, captures full-page screenshots or generates placeholders when needed, and saves annotated evidence images while compiling structured audit results for each record."],"metadata":{"id":"fNVUXwlWrLP6"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a6358971","executionInfo":{"status":"ok","timestamp":1771525833354,"user_tz":180,"elapsed":190644,"user":{"displayName":"Marcos Vinicius Santana","userId":"17193819781821316839"}},"outputId":"500e27f5-e08f-4da9-ca79-f614a02cf32a","collapsed":true},"source":["import re\n","from PIL import Image, ImageDraw, ImageFont\n","import io\n","import textwrap\n","from selenium.common.exceptions import TimeoutException, WebDriverException\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from selenium.webdriver.common.by import By # Corrected import for 'By'\n","from webdriver_manager.chrome import ChromeDriverManager\n","import time\n","import os # Import os for path checking, was missing in original cell\n","import shutil # Import shutil for directory operations\n","import json # Ensure json is imported for parsing Gemini responses\n","import pandas as pd # Import pandas to read the Excel file\n","\n","# 1. Initialize an empty list to store audit results\n","audit_results = []\n","\n","# Define constants for image processing\n","FONT_SIZE = 18\n","HEADER_HEIGHT = 150 # Increased header height to accommodate more text\n","TEXT_MARGIN = 10\n","IMG_WIDTH = 1280 # Assuming fixed width for screenshots\n","\n","# Determine font path dynamically (Colab specific)\n","try:\n","    # This font is usually available in Colab\n","    font_path = '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'\n","    font = ImageFont.truetype(font_path, FONT_SIZE)\n","except IOError:\n","    # Fallback to a default font if LiberationSans is not found\n","    print(\"Warning: LiberationSans-Regular.ttf not found. Using default font.\")\n","    font = Image.load_default_font()\n","\n","# Helper function to sanitize URN for filenames\n","def sanitize_urn(urn):\n","    return re.sub(r'[^a-zA-Z0-9_\\-]', '', urn)\n","\n","# Helper function to create a placeholder image\n","def create_placeholder_image(text, width=IMG_WIDTH, height=500, bg_color=(255, 255, 255), text_color=(0, 0, 0)):\n","    img = Image.new('RGB', (width, height), color=bg_color)\n","    d = ImageDraw.Draw(img)\n","    # Use textbbox instead of textsize, calculate text position\n","    try:\n","        bbox = d.textbbox((0, 0), text, font=font)\n","    except TypeError: # Fallback for font=None with load_default()\n","        bbox = d.textbbox((0, 0), text)\n","\n","    text_width = bbox[2] - bbox[0]\n","    text_height = bbox[3] - bbox[1]\n","    x = (width - text_width) / 2\n","    y = (height - text_height) / 2\n","    d.text((x, y), text, fill=text_color, font=font)\n","    return img\n","\n","print(\"Initialized audit_results list and defined helper functions for image processing.\")\n","\n","# Initialize the Selenium Service and WebDriver globally outside the loop\n","try:\n","    print(\"Initializing Selenium WebDriver...\")\n","    # Assuming `chrome_options` and `model` are globally available from previous successful cells.\n","    service = Service(ChromeDriverManager().install())\n","    driver = webdriver.Chrome(service=service, options=chrome_options)\n","    driver.set_page_load_timeout(15) # 15-second timeout for page loading\n","    print(\"Selenium WebDriver initialized successfully.\")\n","except Exception as e:\n","    print(f\"Error initializing Selenium WebDriver: {e}\")\n","    sys.exit(\"Terminating execution due to WebDriver initialization failure.\")\n","\n","# Load the DataFrame\n","# CHANGE THE FILE CONTENT WITH YOUR FILE' NAME\n","excel_file_path = '/content/19 casos.xlsx'\n","df_quota_relief = pd.read_excel(excel_file_path)\n","print(f\"Loaded DataFrame from {excel_file_path}. Shape: {df_quota_relief.shape}\")\n","\n","# Gemini API specific retry parameters (not used if API is disabled, but kept for context)\n","MAX_RETRIES = 7\n","BASE_DELAY = 40 # seconds\n","\n","# Create evidence directory\n","evidence_dir = 'evidence_screenshots'\n","# Clear existing evidence directory to ensure no old files with colons remain\n","if os.path.exists(evidence_dir):\n","    shutil.rmtree(evidence_dir)\n","os.makedirs(evidence_dir, exist_ok=True)\n","print(f\"Evidence directory created at: {evidence_dir}\")\n","\n","# Initialize a counter for rows that attempted Gemini API calls (not used if API is disabled)\n","gemini_attempted_rows_counter = 0\n","\n","# Removed initial delay before starting the main loop as Gemini API is disabled.\n","\n","# Iterate through each row of the DataFrame\n","for index, row in df_quota_relief.iterrows():\n","    print(f\"\\nProcessing row {index + 1}/{len(df_quota_relief)}\")\n","\n","    # Safely get string values, replacing NaN with appropriate defaults\n","    ai_opp_urn_val = row['AI_OPP_URN']\n","    if pd.isna(ai_opp_urn_val):\n","        ai_opp_urn = f\"UNKNOWN_URN_ROW_{index+1}\" # Provide a unique fallback\n","    else:\n","        ai_opp_urn = str(ai_opp_urn_val)\n","\n","    ai_reason = str(row['AI_REASON']) if pd.notna(row['AI_REASON']) else \"\"\n","    ai_notes = str(row['AI_NOTES']) if pd.notna(row['AI_NOTES']) else \"\"\n","\n","    # Use the original sanitize_urn function\n","    base_sanitized_urn = sanitize_urn(ai_opp_urn)\n","\n","    urls = re.findall(r'https?://[^ ]+', ai_notes)\n","\n","    # Lists to hold data for potential combined screenshot\n","    opp_screenshots = []\n","    opp_scraped_urls = []\n","    opp_image_statuses = []\n","\n","    # --- Modified section to handle multiple URLs and consolidate screenshots ---\n","    if not urls:\n","        print(f\"Row {index + 1}: No URL found in AI_NOTES. Creating NO_URL placeholder.\")\n","        raw_screenshot_pil_img = create_placeholder_image('NO_URL')\n","        scraped_url = 'NO_URL'\n","        image_status = \"NO_URL_PLACEHOLDER\"\n","        output_image_path = os.path.join(evidence_dir, f\"{base_sanitized_urn}_no_url.jpg\")\n","\n","        # Append result for NO_URL case\n","        audit_results.append({\n","            'AI_OPP_URN': ai_opp_urn,\n","            'AI_REASON': ai_reason,\n","            'AI_NOTES': ai_notes,\n","            'Scraped_URL': scraped_url,\n","            'Image_Status': 'REVIEW_MANUALLY', # Always review manually if no URL\n","            'Evidence_Image_Path': output_image_path\n","        })\n","        # Save placeholder image\n","        if raw_screenshot_pil_img:\n","            header_text = f\"AI_NOTES: {ai_notes}\\nAI_REASON: {ai_reason}\\nScraped URL: {scraped_url}\\nImage Status: REVIEW_MANUALLY\"\n","            wrapped_text = \"\\n\".join(textwrap.wrap(header_text, width=int((IMG_WIDTH - 2*TEXT_MARGIN) / (FONT_SIZE * 0.6))))\n","            text_img = Image.new('RGB', (IMG_WIDTH, HEADER_HEIGHT), color=(255, 255, 255))\n","            d = ImageDraw.Draw(text_img)\n","            d.text((TEXT_MARGIN, TEXT_MARGIN), wrapped_text, fill=(0, 0, 0), font=font)\n","            combined_height = HEADER_HEIGHT + raw_screenshot_pil_img.height\n","            combined_img_to_save_pil = Image.new('RGB', (IMG_WIDTH, combined_height), color=(255, 255, 255))\n","            combined_img_to_save_pil.paste(text_img, (0, 0))\n","            combined_img_to_save_pil.paste(raw_screenshot_pil_img, (0, HEADER_HEIGHT))\n","            combined_img_to_save_pil.save(output_image_path)\n","            print(f\"Row {index + 1}: Combined image saved to {output_image_path}\")\n","\n","    else:\n","        # Process each URL for the current row\n","        for url_idx, url in enumerate(urls):\n","            scraped_url = \"N/A\"\n","            raw_screenshot_pil_img = None\n","            image_status = \"IMAGE_ERROR\" # Default initial status for each URL\n","\n","            print(f\"Row {index + 1}, URL {url_idx+1}/{len(urls)}: Processing URL: {url}\")\n","\n","            if any(keyword in url for keyword in ['dynamics', 'linkedin', 'salesforce']):\n","                print(f\"Row {index + 1}, URL {url_idx+1}: Internal link detected: {url}. Creating placeholder.\")\n","                raw_screenshot_pil_img = create_placeholder_image('INTERNAL_LINK')\n","                scraped_url = 'INTERNAL_LINK'\n","                image_status = \"INTERNAL_LINK_PLACEHOLDER\"\n","            else:\n","                try:\n","                    print(f\"Row {index + 1}, URL {url_idx+1}: Navigating to {url}\")\n","                    driver.get(url)\n","\n","                    current_window_width = IMG_WIDTH\n","                    scroll_height = driver.execute_script(\"return Math.max( document.body.scrollHeight, document.body.offsetHeight, document.documentElement.clientHeight, document.documentElement.scrollHeight, document.documentElement.offsetHeight );\")\n","                    MAX_SCREENSHOT_HEIGHT = 16384\n","                    target_height = min(scroll_height + 100, MAX_SCREENSHOT_HEIGHT)\n","                    original_window_size = driver.get_window_size()\n","                    driver.set_window_size(current_window_width, target_height)\n","                    time.sleep(1)\n","\n","                    screenshot_bytes = driver.get_screenshot_as_png()\n","                    raw_screenshot_pil_img = Image.open(io.BytesIO(screenshot_bytes))\n","                    print(f\"Row {index + 1}, URL {url_idx+1}: Successfully navigated and took full-page screenshot for {url}\")\n","                    scraped_url = url\n","                    image_status = \"OK\"\n","                    driver.set_window_size(original_window_size['width'], original_window_size['height'])\n","\n","                except (WebDriverException, TimeoutException) as e:\n","                    print(f\"Row {index + 1}, URL {url_idx+1}: Error navigating to {url} or taking screenshot: {e}. Creating SITE_ERROR placeholder.\")\n","                    raw_screenshot_pil_img = create_placeholder_image(f'SITE_ERROR: {str(e)}')\n","                    scraped_url = 'SITE_ERROR'\n","                    image_status = \"SITE_ERROR\"\n","                except Exception as e:\n","                    print(f\"Row {index + 1}, URL {url_idx+1}: Unexpected error during navigation to {url} or taking screenshot: {e}. Creating SITE_ERROR placeholder.\")\n","                    raw_screenshot_pil_img = create_placeholder_image(f'SITE_ERROR: {str(e)}')\n","                    scraped_url = 'SITE_ERROR'\n","                    image_status = \"SITE_ERROR\"\n","\n","            # Collect results for this URL\n","            if raw_screenshot_pil_img:\n","                opp_screenshots.append(raw_screenshot_pil_img)\n","            opp_scraped_urls.append(scraped_url)\n","            opp_image_statuses.append(image_status)\n","            print(f\"Row {index + 1}, URL {url_idx+1}: Waiting 1 second before next URL.\")\n","            time.sleep(1)\n","\n","        # After processing all URLs for a given row, combine them if any were processed\n","        if opp_screenshots:\n","            # Stitch all screenshots vertically\n","            total_stitched_height = sum(img.height for img in opp_screenshots)\n","            stitched_screenshot = Image.new('RGB', (IMG_WIDTH, total_stitched_height))\n","            current_h = 0\n","            for img in opp_screenshots:\n","                stitched_screenshot.paste(img, (0, current_h))\n","                current_h += img.height\n","\n","            # Determine overall image status for the combined image\n","            summarized_status = \"IMAGE_OK\"\n","            if any(s != \"OK\" for s in opp_image_statuses):\n","                summarized_status = \"REVIEW_MANUALLY\"\n","\n","            # Create header text for the combined image\n","            header_text_parts = [f\"AI_NOTES: {ai_notes}\", f\"AI_REASON: {ai_reason}\"]\n","            for i, url in enumerate(opp_scraped_urls):\n","                header_text_parts.append(f\"Scraped URL {i+1}: {url}\")\n","            header_text_parts.append(f\"Combined Image Status: {summarized_status}\")\n","            header_text = \"\\n\".join(header_text_parts)\n","\n","            wrapped_text = \"\\n\".join(textwrap.wrap(header_text, width=int((IMG_WIDTH - 2*TEXT_MARGIN) / (FONT_SIZE * 0.6))))\n","\n","            text_img = Image.new('RGB', (IMG_WIDTH, HEADER_HEIGHT), color=(255, 255, 255))\n","            d = ImageDraw.Draw(text_img)\n","            d.text((TEXT_MARGIN, TEXT_MARGIN), wrapped_text, fill=(0, 0, 0), font=font)\n","\n","            # Combine header with the stitched screenshot\n","            final_combined_height = HEADER_HEIGHT + stitched_screenshot.height\n","            final_combined_img = Image.new('RGB', (IMG_WIDTH, final_combined_height), color=(255, 255, 255))\n","            final_combined_img.paste(text_img, (0, 0))\n","            final_combined_img.paste(stitched_screenshot, (0, HEADER_HEIGHT))\n","\n","            # Define the single output path for the combined image\n","            output_image_path = os.path.join(evidence_dir, f\"{base_sanitized_urn}.jpg\")\n","            final_combined_img.save(output_image_path)\n","            print(f\"Row {index + 1}: Combined image for '{ai_opp_urn}' saved to {output_image_path}\")\n","\n","            # Append a single audit result for this opportunity\n","            audit_results.append({\n","                'AI_OPP_URN': ai_opp_urn,\n","                'AI_REASON': ai_reason,\n","                'AI_NOTES': ai_notes,\n","                'Scraped_URL': \"; \".join(opp_scraped_urls), # Join all URLs into one string\n","                'Image_Status': summarized_status,\n","                'Evidence_Image_Path': output_image_path\n","            })\n","        else:\n","            # This case means URLs were found in AI_NOTES but all failed to produce any screenshot (e.g., all navigation errors)\n","            # Create a placeholder indicating failure to get any image\n","            print(f\"Row {index + 1}: URLs found but no images generated. Creating NO_IMAGE_GENERATED placeholder.\")\n","            raw_screenshot_pil_img = create_placeholder_image('NO_IMAGE_GENERATED')\n","            scraped_url = \"; \".join(opp_scraped_urls) if opp_scraped_urls else \"N/A\"\n","            image_status = \"REVIEW_MANUALLY\"\n","            output_image_path = os.path.join(evidence_dir, f\"{base_sanitized_urn}_no_image.jpg\")\n","\n","            header_text = f\"AI_NOTES: {ai_notes}\\nAI_REASON: {ai_reason}\\nScraped URL: {scraped_url}\\nImage Status: {image_status}\"\n","            wrapped_text = \"\\n\".join(textwrap.wrap(header_text, width=int((IMG_WIDTH - 2*TEXT_MARGIN) / (FONT_SIZE * 0.6))))\n","            text_img = Image.new('RGB', (IMG_WIDTH, HEADER_HEIGHT), color=(255, 255, 255))\n","            d = ImageDraw.Draw(text_img)\n","            d.text((TEXT_MARGIN, TEXT_MARGIN), wrapped_text, fill=(0, 0, 0), font=font)\n","            combined_height = HEADER_HEIGHT + raw_screenshot_pil_img.height\n","            combined_img_to_save_pil = Image.new('RGB', (IMG_WIDTH, combined_height), color=(255, 255, 255))\n","            combined_img_to_save_pil.paste(text_img, (0, 0))\n","            combined_img_to_save_pil.paste(raw_screenshot_pil_img, (0, HEADER_HEIGHT))\n","            combined_img_to_save_pil.save(output_image_path)\n","\n","            audit_results.append({\n","                'AI_OPP_URN': ai_opp_urn,\n","                'AI_REASON': ai_reason,\n","                'AI_NOTES': ai_notes,\n","                'Scraped_URL': scraped_url,\n","                'Image_Status': image_status,\n","                'Evidence_Image_Path': output_image_path\n","            })\n","\n","\n","    print(f\"Row {index + 1}: Finished processing all URLs. Waiting 1 second before next row.\")\n","    time.sleep(1)\n","\n","# 16. Ensure the driver is quit after the loop\n","if 'driver' in globals() and driver:\n","    driver.quit()\n","    print(\"Selenium WebDriver closed.\")\n","\n","print(\"Finished processing all rows and collecting audit results.\")\n","# Display first few audit results to verify\n","print(\"\\nTotal processed rows: \" + str(len(audit_results)))\n","print(\"\\nFirst 3 audit results:\")\n","for i, result in enumerate(audit_results[:3]):\n","    print(f\"Result {i+1}: {result}\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Initialized audit_results list and defined helper functions for image processing.\n","Initializing Selenium WebDriver...\n","Selenium WebDriver initialized successfully.\n","Loaded DataFrame from /content/19 casos.xlsx. Shape: (19, 44)\n","Evidence directory created at: evidence_screenshots\n","\n","Processing row 1/19\n","Row 1, URL 1/1: Processing URL: https://investor.illumina.com/news/press-release-details/2025/Illumina-to-acquire-SomaLogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy/default.aspx\n","\n","https://www.prnewswire.com/news-releases/illumina-to-acquire-somalogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy-302488151.html\n","Row 1, URL 1: Navigating to https://investor.illumina.com/news/press-release-details/2025/Illumina-to-acquire-SomaLogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy/default.aspx\n","\n","https://www.prnewswire.com/news-releases/illumina-to-acquire-somalogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy-302488151.html\n","Row 1, URL 1: Successfully navigated and took full-page screenshot for https://investor.illumina.com/news/press-release-details/2025/Illumina-to-acquire-SomaLogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy/default.aspx\n","\n","https://www.prnewswire.com/news-releases/illumina-to-acquire-somalogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy-302488151.html\n","Row 1, URL 1: Waiting 1 second before next URL.\n","Row 1: Combined image for 'urnlienterpriseCrmOpportunityBVF5WNYSYUI67H4KAAGTUW6SXI' saved to evidence_screenshots/urnlienterpriseCrmOpportunityBVF5WNYSYUI67H4KAAGTUW6SXI.jpg\n","Row 1: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 2/19\n","Row 2, URL 1/1: Processing URL: https://bluehalo.com/bluehalo-and-eqlipse-technologies-combine-to-create-global-defense-technology-leader/\n","\n","https://bluehalo.com/aerovironment-to-acquire-bluehalo/\n","Row 2, URL 1: Navigating to https://bluehalo.com/bluehalo-and-eqlipse-technologies-combine-to-create-global-defense-technology-leader/\n","\n","https://bluehalo.com/aerovironment-to-acquire-bluehalo/\n","Row 2, URL 1: Successfully navigated and took full-page screenshot for https://bluehalo.com/bluehalo-and-eqlipse-technologies-combine-to-create-global-defense-technology-leader/\n","\n","https://bluehalo.com/aerovironment-to-acquire-bluehalo/\n","Row 2, URL 1: Waiting 1 second before next URL.\n","Row 2: Combined image for 'urnlienterpriseCrmOpportunityPVIS63R6EUI65PPUAAGTUW6SFM' saved to evidence_screenshots/urnlienterpriseCrmOpportunityPVIS63R6EUI65PPUAAGTUW6SFM.jpg\n","Row 2: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 3/19\n","Row 3, URL 1/3: Processing URL: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=opportunity&id=91b2bf0d-6432-ef11-840a-000d3a597adb\n","\n","Kaseya\n","Row 3, URL 1: Internal link detected: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=opportunity&id=91b2bf0d-6432-ef11-840a-000d3a597adb\n","\n","Kaseya. Creating placeholder.\n","Row 3, URL 1: Waiting 1 second before next URL.\n","Row 3, URL 2/3: Processing URL: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=account&id=175c81af-314c-e811-a952-000d3a30da56\n","\n","Press\n","Row 3, URL 2: Internal link detected: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=account&id=175c81af-314c-e811-a952-000d3a30da56\n","\n","Press. Creating placeholder.\n","Row 3, URL 2: Waiting 1 second before next URL.\n","Row 3, URL 3/3: Processing URL: https://www.kaseya.com/press-release/kaseya-extends-community-investment-with-addition-of-technology-marketing-toolkit/\n","Row 3, URL 3: Navigating to https://www.kaseya.com/press-release/kaseya-extends-community-investment-with-addition-of-technology-marketing-toolkit/\n","Row 3, URL 3: Successfully navigated and took full-page screenshot for https://www.kaseya.com/press-release/kaseya-extends-community-investment-with-addition-of-technology-marketing-toolkit/\n","Row 3, URL 3: Waiting 1 second before next URL.\n","Row 3: Combined image for 'urnlienterpriseCrmOpportunityBW73FEJSMQI67BAKAAGTUWL23M' saved to evidence_screenshots/urnlienterpriseCrmOpportunityBW73FEJSMQI67BAKAAGTUWL23M.jpg\n","Row 3: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 4/19\n","Row 4, URL 1/2: Processing URL: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&pagetype=entityrecord&etn=account&id=ff6b1b4b-1b4c-e811-a952-000d3a30d7c8\n","\n","Proof\n","Row 4, URL 1: Internal link detected: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&pagetype=entityrecord&etn=account&id=ff6b1b4b-1b4c-e811-a952-000d3a30d7c8\n","\n","Proof. Creating placeholder.\n","Row 4, URL 1: Waiting 1 second before next URL.\n","Row 4, URL 2/2: Processing URL: https://www.onenetwork.com/2024/08/blue-yonder-acquires-one-network-enterprises/\n","Row 4, URL 2: Navigating to https://www.onenetwork.com/2024/08/blue-yonder-acquires-one-network-enterprises/\n","Row 4, URL 2: Successfully navigated and took full-page screenshot for https://www.onenetwork.com/2024/08/blue-yonder-acquires-one-network-enterprises/\n","Row 4, URL 2: Waiting 1 second before next URL.\n","Row 4: Combined image for 'urnlienterpriseCrmOpportunityXNQLPWLR2YI65DPQAAGTUW6XAI' saved to evidence_screenshots/urnlienterpriseCrmOpportunityXNQLPWLR2YI65DPQAAGTUW6XAI.jpg\n","Row 4: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 5/19\n","Row 5, URL 1/2: Processing URL: https://www.quanterix.com/press-releases/quanterix-completes-acquisition-of-akoya-biosciences-creating-the-first-integrated-platform-capable-of-measuring-biomarkers-across-the-blood-and-tissue-continuum/\n","\n","Row 5, URL 1: Navigating to https://www.quanterix.com/press-releases/quanterix-completes-acquisition-of-akoya-biosciences-creating-the-first-integrated-platform-capable-of-measuring-biomarkers-across-the-blood-and-tissue-continuum/\n","\n","Row 5, URL 1: Successfully navigated and took full-page screenshot for https://www.quanterix.com/press-releases/quanterix-completes-acquisition-of-akoya-biosciences-creating-the-first-integrated-platform-capable-of-measuring-biomarkers-across-the-blood-and-tissue-continuum/\n","\n","Row 5, URL 1: Waiting 1 second before next URL.\n","Row 5, URL 2/2: Processing URL: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&newWindow=true&pagetype=entityrecord&etn=incident&id=29cb5f36-bcba-f011-bbd3-000d3a5a7c1f\n","Row 5, URL 2: Internal link detected: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&newWindow=true&pagetype=entityrecord&etn=incident&id=29cb5f36-bcba-f011-bbd3-000d3a5a7c1f. Creating placeholder.\n","Row 5, URL 2: Waiting 1 second before next URL.\n","Row 5: Combined image for 'urnlienterpriseCrmOpportunityUK75AFUWHEI67LBBAAGTUWK2PA' saved to evidence_screenshots/urnlienterpriseCrmOpportunityUK75AFUWHEI67LBBAAGTUWK2PA.jpg\n","Row 5: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 6/19\n","Row 6, URL 1/1: Processing URL: https://breakingdefense.com/2024/12/rheinmetall-closes-loc-performance-acquisition-as-it-eyes-us-market-expansion/?utm_source=chatgpt.com\n","Row 6, URL 1: Navigating to https://breakingdefense.com/2024/12/rheinmetall-closes-loc-performance-acquisition-as-it-eyes-us-market-expansion/?utm_source=chatgpt.com\n","Row 6, URL 1: Successfully navigated and took full-page screenshot for https://breakingdefense.com/2024/12/rheinmetall-closes-loc-performance-acquisition-as-it-eyes-us-market-expansion/?utm_source=chatgpt.com\n","Row 6, URL 1: Waiting 1 second before next URL.\n","Row 6: Combined image for 'urnlienterpriseCrmOpportunityUX74QLMBWYI67JTQAAGTUMVTKQ' saved to evidence_screenshots/urnlienterpriseCrmOpportunityUX74QLMBWYI67JTQAAGTUMVTKQ.jpg\n","Row 6: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 7/19\n","Row 7, URL 1/1: Processing URL: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=account&id=d9e70f89-e54c-e811-a952-000d3a30d104\n","\n","https://pditechnologies.com/news/pdi-acquires-nuspire/\n","Row 7, URL 1: Internal link detected: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=account&id=d9e70f89-e54c-e811-a952-000d3a30d104\n","\n","https://pditechnologies.com/news/pdi-acquires-nuspire/. Creating placeholder.\n","Row 7, URL 1: Waiting 1 second before next URL.\n","Row 7: Combined image for 'urnlienterpriseCrmOpportunityGXGZPQDFEEI63FK7AAREQCZSPE' saved to evidence_screenshots/urnlienterpriseCrmOpportunityGXGZPQDFEEI63FK7AAREQCZSPE.jpg\n","Row 7: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 8/19\n","Row 8, URL 1/1: Processing URL: https://investor.rbglobal.com/news/news-details/2023/Ritchie-Bros.-Completes-Acquisition-of-IAA-Creating-a-Premier-Global-Marketplace-Leader/default.aspx\n","\n","the\n","Row 8, URL 1: Navigating to https://investor.rbglobal.com/news/news-details/2023/Ritchie-Bros.-Completes-Acquisition-of-IAA-Creating-a-Premier-Global-Marketplace-Leader/default.aspx\n","\n","the\n","Row 8, URL 1: Successfully navigated and took full-page screenshot for https://investor.rbglobal.com/news/news-details/2023/Ritchie-Bros.-Completes-Acquisition-of-IAA-Creating-a-Premier-Global-Marketplace-Leader/default.aspx\n","\n","the\n","Row 8, URL 1: Waiting 1 second before next URL.\n","Row 8: Combined image for 'urnlienterpriseCrmOpportunity4G6XEHLF4YI63FK7AAREQCZSPE' saved to evidence_screenshots/urnlienterpriseCrmOpportunity4G6XEHLF4YI63FK7AAREQCZSPE.jpg\n","Row 8: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 9/19\n","Row 9, URL 1/4: Processing URL: https://www.matw.com/investors/news-events/press-releases/detail/260/matthews-international-to-sell-sgk-brand-solutionsws\n","Row 9, URL 1: Navigating to https://www.matw.com/investors/news-events/press-releases/detail/260/matthews-international-to-sell-sgk-brand-solutionsws\n","Row 9, URL 1: Successfully navigated and took full-page screenshot for https://www.matw.com/investors/news-events/press-releases/detail/260/matthews-international-to-sell-sgk-brand-solutionsws\n","Row 9, URL 1: Waiting 1 second before next URL.\n","Row 9, URL 2/4: Processing URL: https://www.matw.com/investors/news-events/press-releases/detail/271/matthews-international-to-sell-remaining-operatingSell\n","Row 9, URL 2: Navigating to https://www.matw.com/investors/news-events/press-releases/detail/271/matthews-international-to-sell-remaining-operatingSell\n","Row 9, URL 2: Successfully navigated and took full-page screenshot for https://www.matw.com/investors/news-events/press-releases/detail/271/matthews-international-to-sell-remaining-operatingSell\n","Row 9, URL 2: Waiting 1 second before next URL.\n","Row 9, URL 3/4: Processing URL: https://www.globenewswire.com/news-release/2025/11/13/3187427/12919/en/Matthews-International-Announces-Sale-of-Warehouse-Automation-Business-for-230-million.html\n","\n","\n","Revenue,\n","Row 9, URL 3: Navigating to https://www.globenewswire.com/news-release/2025/11/13/3187427/12919/en/Matthews-International-Announces-Sale-of-Warehouse-Automation-Business-for-230-million.html\n","\n","\n","Revenue,\n","Row 9, URL 3: Successfully navigated and took full-page screenshot for https://www.globenewswire.com/news-release/2025/11/13/3187427/12919/en/Matthews-International-Announces-Sale-of-Warehouse-Automation-Business-for-230-million.html\n","\n","\n","Revenue,\n","Row 9, URL 3: Waiting 1 second before next URL.\n","Row 9, URL 4/4: Processing URL: https://www.matw.com/investors/news-events/press-releases/detail/286/matthews-international-reports-results-for-fiscal-2025rts\n","Row 9, URL 4: Navigating to https://www.matw.com/investors/news-events/press-releases/detail/286/matthews-international-reports-results-for-fiscal-2025rts\n","Row 9, URL 4: Successfully navigated and took full-page screenshot for https://www.matw.com/investors/news-events/press-releases/detail/286/matthews-international-reports-results-for-fiscal-2025rts\n","Row 9, URL 4: Waiting 1 second before next URL.\n","Row 9: Combined image for 'urnlienterpriseCrmOpportunity3QQRD5T37AI63ANJAAREQBHGBM' saved to evidence_screenshots/urnlienterpriseCrmOpportunity3QQRD5T37AI63ANJAAREQBHGBM.jpg\n","Row 9: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 10/19\n","Row 10, URL 1/1: Processing URL: https://www.chevron.com/newsroom/2025/q3/chevron-completes-acquisition-of-hess-corporation#:~:text=Chevron%20Completes%20Acquisition%20of%20Hess%20Corporation%20%E2%80%94%20Chevron\n","Row 10, URL 1: Navigating to https://www.chevron.com/newsroom/2025/q3/chevron-completes-acquisition-of-hess-corporation#:~:text=Chevron%20Completes%20Acquisition%20of%20Hess%20Corporation%20%E2%80%94%20Chevron\n","Row 10, URL 1: Successfully navigated and took full-page screenshot for https://www.chevron.com/newsroom/2025/q3/chevron-completes-acquisition-of-hess-corporation#:~:text=Chevron%20Completes%20Acquisition%20of%20Hess%20Corporation%20%E2%80%94%20Chevron\n","Row 10, URL 1: Waiting 1 second before next URL.\n","Row 10: Combined image for 'urnlienterpriseCrmOpportunityJOW3BQ2FVQI63HNPAAGTUM3JUY' saved to evidence_screenshots/urnlienterpriseCrmOpportunityJOW3BQ2FVQI63HNPAAGTUM3JUY.jpg\n","Row 10: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 11/19\n","Row 11, URL 1/1: Processing URL: https://www.nytimes.com/2022/01/06/business/new-york-times-the-athletic.html\n","Row 11, URL 1: Navigating to https://www.nytimes.com/2022/01/06/business/new-york-times-the-athletic.html\n","Row 11, URL 1: Successfully navigated and took full-page screenshot for https://www.nytimes.com/2022/01/06/business/new-york-times-the-athletic.html\n","Row 11, URL 1: Waiting 1 second before next URL.\n","Row 11: Combined image for 'urnlienterpriseCrmOpportunitySS2ICPDWXAI67JTQAAREQCLYNE' saved to evidence_screenshots/urnlienterpriseCrmOpportunitySS2ICPDWXAI67JTQAAREQCLYNE.jpg\n","Row 11: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 12/19\n","Row 12, URL 1/2: Processing URL: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&pagetype=entityrecord&etn=account&id=3081d521-1f4c-e811-a952-000d3a30dc28.\n","\n","Here\n","Row 12, URL 1: Internal link detected: https://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&pagetype=entityrecord&etn=account&id=3081d521-1f4c-e811-a952-000d3a30dc28.\n","\n","Here. Creating placeholder.\n","Row 12, URL 1: Waiting 1 second before next URL.\n","Row 12, URL 2/2: Processing URL: https://ascendion.com/press-releases/ascendion-acquires-moodys-to-strengthen-product-leadership-in-ai-era/\n","Row 12, URL 2: Navigating to https://ascendion.com/press-releases/ascendion-acquires-moodys-to-strengthen-product-leadership-in-ai-era/\n","Row 12, URL 2: Successfully navigated and took full-page screenshot for https://ascendion.com/press-releases/ascendion-acquires-moodys-to-strengthen-product-leadership-in-ai-era/\n","Row 12, URL 2: Waiting 1 second before next URL.\n","Row 12: Combined image for 'urnlienterpriseCrmOpportunity6MWCDHMVPUI67LBBAAGTUMVTKQ' saved to evidence_screenshots/urnlienterpriseCrmOpportunity6MWCDHMVPUI67LBBAAGTUMVTKQ.jpg\n","Row 12: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 13/19\n","Row 13, URL 1/1: Processing URL: https://hotelsmag.com/news/donohoe-hospitality-manages-maryland-hotel-portfolio/#:~:text=Donohoe%20Hospitality%20Services%20has%20been%20chosen%20to,by%20Southern%20Management%20Companies%2C%20totaling%20597%20rooms\n","Row 13, URL 1: Navigating to https://hotelsmag.com/news/donohoe-hospitality-manages-maryland-hotel-portfolio/#:~:text=Donohoe%20Hospitality%20Services%20has%20been%20chosen%20to,by%20Southern%20Management%20Companies%2C%20totaling%20597%20rooms\n","Row 13, URL 1: Successfully navigated and took full-page screenshot for https://hotelsmag.com/news/donohoe-hospitality-manages-maryland-hotel-portfolio/#:~:text=Donohoe%20Hospitality%20Services%20has%20been%20chosen%20to,by%20Southern%20Management%20Companies%2C%20totaling%20597%20rooms\n","Row 13, URL 1: Waiting 1 second before next URL.\n","Row 13: Combined image for 'urnlienterpriseCrmOpportunityUEQIV4FHQYI67CTKAAGTUWPKPI' saved to evidence_screenshots/urnlienterpriseCrmOpportunityUEQIV4FHQYI67CTKAAGTUWPKPI.jpg\n","Row 13: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 14/19\n","Row 14, URL 1/1: Processing URL: https://www.paymentsdive.com/news/fidelity-national-information-payments-software-everlink-acquisitions/756938/\n","Row 14, URL 1: Navigating to https://www.paymentsdive.com/news/fidelity-national-information-payments-software-everlink-acquisitions/756938/\n","Row 14, URL 1: Successfully navigated and took full-page screenshot for https://www.paymentsdive.com/news/fidelity-national-information-payments-software-everlink-acquisitions/756938/\n","Row 14, URL 1: Waiting 1 second before next URL.\n","Row 14: Combined image for 'urnlienterpriseCrmOpportunityMJB2I4MGIYI67LBBAAGTUWK2PA' saved to evidence_screenshots/urnlienterpriseCrmOpportunityMJB2I4MGIYI67LBBAAGTUWK2PA.jpg\n","Row 14: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 15/19\n","Row 15, URL 1/1: Processing URL: https://www.uwindsor.ca/itservices/2020-09-16/linkedin-learning-access-expire\n","\n","https://www.linkedin.com/pulse/perfect-storm-canadas-post-secondary-education-crisis-tracey-8brbc/\n","Row 15, URL 1: Internal link detected: https://www.uwindsor.ca/itservices/2020-09-16/linkedin-learning-access-expire\n","\n","https://www.linkedin.com/pulse/perfect-storm-canadas-post-secondary-education-crisis-tracey-8brbc/. Creating placeholder.\n","Row 15, URL 1: Waiting 1 second before next URL.\n","Row 15: Combined image for 'urnlienterpriseCrmOpportunity7IPAQA27FII67P7DMBC32B6VSI' saved to evidence_screenshots/urnlienterpriseCrmOpportunity7IPAQA27FII67P7DMBC32B6VSI.jpg\n","Row 15: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 16/19\n","Row 16, URL 1/1: Processing URL: https://www.aura.com/press/release/aura-splits-into-two-world-class-online-safety-companies\n","Row 16, URL 1: Navigating to https://www.aura.com/press/release/aura-splits-into-two-world-class-online-safety-companies\n","Row 16, URL 1: Successfully navigated and took full-page screenshot for https://www.aura.com/press/release/aura-splits-into-two-world-class-online-safety-companies\n","Row 16, URL 1: Waiting 1 second before next URL.\n","Row 16: Combined image for 'urnlienterpriseCrmOpportunityUO6PL4SDOAI65PPUAAGTUW6V64' saved to evidence_screenshots/urnlienterpriseCrmOpportunityUO6PL4SDOAI65PPUAAGTUW6V64.jpg\n","Row 16: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 17/19\n","Row 17, URL 1/2: Processing URL: https://www.accountingtoday.com/news/withum-acquires-pkf-texas\n","\n","Article\n","Row 17, URL 1: Navigating to https://www.accountingtoday.com/news/withum-acquires-pkf-texas\n","\n","Article\n","Row 17, URL 1: Successfully navigated and took full-page screenshot for https://www.accountingtoday.com/news/withum-acquires-pkf-texas\n","\n","Article\n","Row 17, URL 1: Waiting 1 second before next URL.\n","Row 17, URL 2/2: Processing URL: https://www.internationalaccountingbulletin.com/news/withum-pkf-texas-merger/\n","Row 17, URL 2: Navigating to https://www.internationalaccountingbulletin.com/news/withum-pkf-texas-merger/\n","Row 17, URL 2: Successfully navigated and took full-page screenshot for https://www.internationalaccountingbulletin.com/news/withum-pkf-texas-merger/\n","Row 17, URL 2: Waiting 1 second before next URL.\n","Row 17: Combined image for 'urnlienterpriseCrmOpportunityCAJCMU2J4UI67BALAAGTUW6RNU' saved to evidence_screenshots/urnlienterpriseCrmOpportunityCAJCMU2J4UI67BALAAGTUW6RNU.jpg\n","Row 17: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 18/19\n","Row 18, URL 1/2: Processing URL: https://www.businesswire.com/news/home/20250127100647/en/OPEXUS-and-Casepoint-Announce-Merger-and-Majority-Investment-from-Thoma-Bravo\n","\n","Everything\n","Row 18, URL 1: Navigating to https://www.businesswire.com/news/home/20250127100647/en/OPEXUS-and-Casepoint-Announce-Merger-and-Majority-Investment-from-Thoma-Bravo\n","\n","Everything\n","Row 18, URL 1: Successfully navigated and took full-page screenshot for https://www.businesswire.com/news/home/20250127100647/en/OPEXUS-and-Casepoint-Announce-Merger-and-Majority-Investment-from-Thoma-Bravo\n","\n","Everything\n","Row 18, URL 1: Waiting 1 second before next URL.\n","Row 18, URL 2/2: Processing URL: https://www.casepoint.com/press/opexus-casepoint-merger-and-majority-investment-from-thoma-bravo/\n","Row 18, URL 2: Navigating to https://www.casepoint.com/press/opexus-casepoint-merger-and-majority-investment-from-thoma-bravo/\n","Row 18, URL 2: Successfully navigated and took full-page screenshot for https://www.casepoint.com/press/opexus-casepoint-merger-and-majority-investment-from-thoma-bravo/\n","Row 18, URL 2: Waiting 1 second before next URL.\n","Row 18: Combined image for 'urnlienterpriseCrmOpportunityLRSBMVZOHII67BAKMBC32BD6I4' saved to evidence_screenshots/urnlienterpriseCrmOpportunityLRSBMVZOHII67BAKMBC32BD6I4.jpg\n","Row 18: Finished processing all URLs. Waiting 1 second before next row.\n","\n","Processing row 19/19\n","Row 19, URL 1/3: Processing URL: https://itgcomm.com/press-release/tilson-selects-itg-communications\n","\n","Tilson\n","Row 19, URL 1: Navigating to https://itgcomm.com/press-release/tilson-selects-itg-communications\n","\n","Tilson\n","Row 19, URL 1: Successfully navigated and took full-page screenshot for https://itgcomm.com/press-release/tilson-selects-itg-communications\n","\n","Tilson\n","Row 19, URL 1: Waiting 1 second before next URL.\n","Row 19, URL 2/3: Processing URL: https://tilsontech.com/news-and-insights/press-releases/tilson-takes-steps-to-position-the-company-for-long-term-success/\n","\n","Court\n","Row 19, URL 2: Navigating to https://tilsontech.com/news-and-insights/press-releases/tilson-takes-steps-to-position-the-company-for-long-term-success/\n","\n","Court\n","Row 19, URL 2: Successfully navigated and took full-page screenshot for https://tilsontech.com/news-and-insights/press-releases/tilson-takes-steps-to-position-the-company-for-long-term-success/\n","\n","Court\n","Row 19, URL 2: Waiting 1 second before next URL.\n","Row 19, URL 3/3: Processing URL: https://tilsontech.com/news-and-insights/press-releases/tilson-receives-final-court-approval-of-key-business-continuity-motions/\n","Row 19, URL 3: Navigating to https://tilsontech.com/news-and-insights/press-releases/tilson-receives-final-court-approval-of-key-business-continuity-motions/\n","Row 19, URL 3: Successfully navigated and took full-page screenshot for https://tilsontech.com/news-and-insights/press-releases/tilson-receives-final-court-approval-of-key-business-continuity-motions/\n","Row 19, URL 3: Waiting 1 second before next URL.\n","Row 19: Combined image for 'urnlienterpriseCrmOpportunityOTVSLEKACII63HNPAAGTUM3MH4' saved to evidence_screenshots/urnlienterpriseCrmOpportunityOTVSLEKACII63HNPAAGTUM3MH4.jpg\n","Row 19: Finished processing all URLs. Waiting 1 second before next row.\n","Selenium WebDriver closed.\n","Finished processing all rows and collecting audit results.\n","\n","Total processed rows: 19\n","\n","First 3 audit results:\n","Result 1: {'AI_OPP_URN': 'urnlienterpriseCrmOpportunityBVF5WNYSYUI67H4KAAGTUW6SXI', 'AI_REASON': 'Merger / Acquisition', 'AI_NOTES': 'Selling SOMA Logic division to Illumina - Going through M&A: See Next STeps and URL verifcation here:\\n\\nhttps://investor.illumina.com/news/press-release-details/2025/Illumina-to-acquire-SomaLogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy/default.aspx\\n\\nhttps://www.prnewswire.com/news-releases/illumina-to-acquire-somalogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy-302488151.html', 'Scraped_URL': 'https://investor.illumina.com/news/press-release-details/2025/Illumina-to-acquire-SomaLogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy/default.aspx\\n\\nhttps://www.prnewswire.com/news-releases/illumina-to-acquire-somalogic-accelerating-its-proteomics-business-and-advancing-the-companys-multiomics-strategy-302488151.html', 'Image_Status': 'IMAGE_OK', 'Evidence_Image_Path': 'evidence_screenshots/urnlienterpriseCrmOpportunityBVF5WNYSYUI67H4KAAGTUW6SXI.jpg'}\n","Result 2: {'AI_OPP_URN': 'urnlienterpriseCrmOpportunityPVIS63R6EUI65PPUAAGTUW6SFM', 'AI_REASON': 'Merger / Acquisition', 'AI_NOTES': 'Acquired by BlueHalo, then Aerovironment, Inc -\\n\\nhttps://bluehalo.com/bluehalo-and-eqlipse-technologies-combine-to-create-global-defense-technology-leader/\\n\\nhttps://bluehalo.com/aerovironment-to-acquire-bluehalo/', 'Scraped_URL': 'https://bluehalo.com/bluehalo-and-eqlipse-technologies-combine-to-create-global-defense-technology-leader/\\n\\nhttps://bluehalo.com/aerovironment-to-acquire-bluehalo/', 'Image_Status': 'IMAGE_OK', 'Evidence_Image_Path': 'evidence_screenshots/urnlienterpriseCrmOpportunityPVIS63R6EUI65PPUAAGTUW6SFM.jpg'}\n","Result 3: {'AI_OPP_URN': 'urnlienterpriseCrmOpportunityBW73FEJSMQI67BAKAAGTUWL23M', 'AI_REASON': 'Merger / Acquisition', 'AI_NOTES': 'Quota Relief Opp Request:\\n\\nTechnology Marketing Toolkit:\\nhttps://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=opportunity&id=91b2bf0d-6432-ef11-840a-000d3a597adb\\n\\nKaseya (Acquired Technology Marketing Toolkit): \\nhttps://li.crm.dynamics.com/main.aspx?appid=5e091888-3bba-e911-a97f-000d3a37d833&forceUCI=1&pagetype=entityrecord&etn=account&id=175c81af-314c-e811-a952-000d3a30da56\\n\\nPress Release of Acquisition: https://www.kaseya.com/press-release/kaseya-extends-community-investment-with-addition-of-technology-marketing-toolkit/', 'Scraped_URL': 'INTERNAL_LINK; INTERNAL_LINK; https://www.kaseya.com/press-release/kaseya-extends-community-investment-with-addition-of-technology-marketing-toolkit/', 'Image_Status': 'REVIEW_MANUALLY', 'Evidence_Image_Path': 'evidence_screenshots/urnlienterpriseCrmOpportunityBW73FEJSMQI67BAKAAGTUWL23M.jpg'}\n"]}]},{"cell_type":"markdown","source":["## **Audit Results Export and Evidence Archiving**\n","\n","Description:\n","This section converts the collected audit results into a DataFrame, exports them to an Excel file, and packages all generated evidence images into a ZIP archive for easy download and review."],"metadata":{"id":"1MyIttLBrXZb"}},{"cell_type":"code","source":["import pandas as pd\n","import zipfile\n","import os\n","\n","# 1. Convert audit_results list to a pandas DataFrame\n","df_final_audit = pd.DataFrame(audit_results)\n","print(\"Audit results converted to DataFrame.\")\n","\n","# 2. Save the DataFrame to an Excel file\n","output_excel_path = 'final_audit_results.xlsx'\n","df_final_audit.to_excel(output_excel_path, index=True)\n","print(f\"Final audit results saved to {output_excel_path}\")\n","\n","# 3. Create a zip archive of the evidence_images directory\n","zip_filename = 'evidence_images.zip'\n","with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","    for root, _, files in os.walk(evidence_dir):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            zipf.write(file_path, os.path.relpath(file_path, evidence_dir))\n","print(f\"Evidence images archived to {zip_filename}\")\n","\n","print(\"Finished generating output file and archiving evidence images.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZbiueOgcTdpL","executionInfo":{"status":"ok","timestamp":1771525834123,"user_tz":180,"elapsed":744,"user":{"displayName":"Marcos Vinicius Santana","userId":"17193819781821316839"}},"outputId":"505b5232-11dd-4bc7-cfba-833c74311caf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Audit results converted to DataFrame.\n","Final audit results saved to final_audit_results.xlsx\n","Evidence images archived to evidence_images.zip\n","Finished generating output file and archiving evidence images.\n"]}]}]}